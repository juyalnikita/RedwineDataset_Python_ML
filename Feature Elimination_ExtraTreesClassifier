from sklearn import linear_model
from sklearn import datasets,metrics
from sklearn.ensemble import ExtraTreesClassifier
import pandas as pd
import numpy as np
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
d=pd.read_csv('C:/Users/Nikita Juyal/Desktop/ML Assignment/winequality-red.csv')
model=ExtraTreesClassifier()
#model = LogisticRegression()

train_column=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']
target_column=['quality']

X=d[train_column]
Y=d[target_column]

model.fit(X,Y)
fi=model.feature_importances_
print(fi)

# To drop column 4,6 and 7 which were least ranked as per rfe
X.drop(X.columns[[0,3,4,5,8]], axis=1, inplace=True)
#print(X)


X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.20, random_state = 20)

#Random Forest
clf = RandomForestClassifier()
clf.fit(X_train,Y_train)
predict = clf.predict(X_test)
cf = confusion_matrix(predict,Y_test)
print(cf)
print(accuracy_score(predict,Y_test))
